{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuwenzhuo/.conda/envs/gnn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "import warnings\n",
    "from logging import getLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from recbole.utils import init_seed, set_color\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from config.configuration import Config\n",
    "from data.dataset import GeneralDataset, GeneralGraphDataset\n",
    "from data.utils import data_reparation\n",
    "from models.embedding import (EmbeddingHelper, EmbeddingModel, EmbeddingType,\n",
    "                              TemplateType)\n",
    "from trainer import Trainer\n",
    "from utils.logger import init_logger\n",
    "from utils.utils import get_flops, get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--dataset\", \"-d\", type=str, default=\"wsdream-tp\", help=\"name of datasets\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--model\", \"-m\", type=str, default=\"XXX\", help=\"name of models\"\n",
    ")\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "config = Config(model=args.model, dataset=args.dataset)\n",
    "\n",
    "dataset = GeneralGraphDataset(config)\n",
    "train_data, test_data = data_reparation(config, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.user_feat[\"country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_embedding(dataset, template_type:TemplateType):\n",
    "    eh = EmbeddingHelper()\n",
    "    user_invocations = {}\n",
    "    item_invocations = {}\n",
    "    for uid in dataset.uids_in_inter_feat:\n",
    "        user_invocations[uid] = dataset.inter_data_by_type(\"user\", uid)\n",
    "    for iid in dataset.iids_in_inter_feat:\n",
    "        item_invocations[iid] = dataset.inter_data_by_type(\"item\", iid)\n",
    "    # user_embedding = torch.Tensor(eh.fit(EmbeddingType.USER, template_type,\n",
    "    #                                 EmbeddingModel.INSTRUCTOR_BGE_SMALL, invocations=user_invocations, auto_save=False))\n",
    "    # item_embedding = torch.Tensor(eh.fit(EmbeddingType.ITEM, template_type,\n",
    "    #                                 EmbeddingModel.INSTRUCTOR_BGE_SMALL, invocations=item_invocations, auto_save=False))\n",
    "    \n",
    "    user_embedding = torch.nn.Embedding(\n",
    "            num_embeddings=339, embedding_dim=384).weight\n",
    "    item_embedding = torch.nn.Embedding(\n",
    "            num_embeddings=5825, embedding_dim=384).weight\n",
    "    return user_embedding,item_embedding\n",
    "\n",
    "u_embedding, i_embedding = get_pretrained_embedding(train_data.dataset, TemplateType.IMPROVED)\n",
    "\n",
    "uids = list(range(len(u_embedding)))\n",
    "iids = list(range(len(i_embedding)))\n",
    "\n",
    "writer.add_embedding(u_embedding, metadata=uids, tag=\"User Embeddings - DEFAULT\")\n",
    "writer.add_embedding(i_embedding, metadata=iids, tag=\"Item Embeddings - DEFAULT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_embedding(dataset, template_type:TemplateType):\n",
    "    eh = EmbeddingHelper()\n",
    "    user_invocations = {}\n",
    "    item_invocations = {}\n",
    "    for uid in dataset.uids_in_inter_feat:\n",
    "        user_invocations[uid] = dataset.inter_data_by_type(\"user\", uid)\n",
    "    for iid in dataset.iids_in_inter_feat:\n",
    "        item_invocations[iid] = dataset.inter_data_by_type(\"item\", iid)\n",
    "    user_embedding = torch.Tensor(eh.fit(EmbeddingType.USER, template_type,\n",
    "                                    EmbeddingModel.INSTRUCTOR_BGE_SMALL, invocations=user_invocations, auto_save=False))\n",
    "    item_embedding = torch.Tensor(eh.fit(EmbeddingType.ITEM, template_type,\n",
    "                                    EmbeddingModel.INSTRUCTOR_BGE_SMALL, invocations=item_invocations, auto_save=False))\n",
    "    \n",
    "    return user_embedding, item_embedding\n",
    "\n",
    "u_embedding, i_embedding = get_pretrained_embedding(train_data.dataset, TemplateType.IMPROVED)\n",
    "\n",
    "uids = dataset.user_feat[\"country\"].tolist()\n",
    "iids = dataset.item_feat[\"country\"].tolist()\n",
    "\n",
    "writer.add_embedding(u_embedding, metadata=uids, tag=\"User Embeddings - IMPROVED_country\")\n",
    "writer.add_embedding(i_embedding, metadata=iids, tag=\"Item Embeddings - IMPROVED_country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.embeddings import (HuggingFaceEmbeddings,\n",
    "                                  HuggingFaceInstructEmbeddings)\n",
    "\n",
    "from models.embedding.template import BasicTempalte, ImprovedTemplate, StaticTemplate\n",
    "from root import ORIGINAL_DATASET_DIR, RESOURCE_DIR\n",
    "from utils.enums import *\n",
    "\n",
    "embedding_models = {\n",
    "    \"il\": (HuggingFaceInstructEmbeddings, \"hkunlp/instructor-large\"),\n",
    "    \"e5\": (HuggingFaceInstructEmbeddings, \"intfloat/e5-large-v2\"),\n",
    "    \"ixl\": (HuggingFaceInstructEmbeddings, \"hkunlp/instructor-xl\"),\n",
    "    \"bge-small\": (HuggingFaceInstructEmbeddings, \"BAAI/bge-small-en\"),\n",
    "    \"bge-large\": (HuggingFaceInstructEmbeddings, \"BAAI/bge-large-en-v1.5\"),\n",
    "    \"bge-base\": (HuggingFaceInstructEmbeddings, \"BAAI/bge-base-en-v1.5\")\n",
    "}\n",
    "\n",
    "class EmbeddingHelper:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.upath = os.path.join(ORIGINAL_DATASET_DIR, \"userlist.txt\")\n",
    "        self.ipath = os.path.join(ORIGINAL_DATASET_DIR, \"wslist.txt\")\n",
    "        self.suffix = \".npy\"\n",
    "        self._load_user_and_item()\n",
    "\n",
    "    @property\n",
    "    def _user_info_header(self):\n",
    "        return [\"user_id\", \"ip_address\", \"country\", \"ip_number\", \"AS\", \"latitude\", \"longitude\"]\n",
    "\n",
    "    @property\n",
    "    def _item_info_header(self):\n",
    "        return [\"service_id\", \"wsdl_address\", \"provider\", \"ip_address\", \"country\", \"ip_number\", \"AS\", \"latitude\", \"longitude\"]\n",
    "\n",
    "    def _load_user_and_item(self):\n",
    "        self.user_info = pd.read_csv(\n",
    "            self.upath, sep=\"\\t\", header=0, names=self._user_info_header)\n",
    "        self.item_info = pd.read_csv(\n",
    "            self.ipath, sep=\"\\t\", header=0, names=self._item_info_header)\n",
    "\n",
    "    def info2template(self, type_: EmbeddingType, template_type: TemplateType, invocations: Dict[str, List]) -> List[str]:\n",
    "        if type_ == EmbeddingType.USER:\n",
    "            info = self.user_info\n",
    "            id_label = \"user_id\"\n",
    "        else:\n",
    "            info = self.item_info\n",
    "            id_label = \"service_id\"\n",
    "\n",
    "        if template_type == TemplateType.BASIC:\n",
    "            template_func = BasicTempalte\n",
    "        elif template_type == TemplateType.IMPROVED:\n",
    "            template_func = ImprovedTemplate\n",
    "        elif template_type == TemplateType.STATIC:\n",
    "            template_func = StaticTemplate\n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        res = []\n",
    "        print(len(info))\n",
    "        for row_dict in info.to_dict(orient=\"records\"):\n",
    "            id_ = row_dict[id_label]\n",
    "            if issubclass(template_func, BasicTempalte):\n",
    "                template = template_func(row_dict)\n",
    "            else:\n",
    "                if type_ == EmbeddingType.USER:\n",
    "                    template = template_func(\n",
    "                        type=\"user\", invocations=invocations.get(id_, []), content=row_dict)  # type: ignore\n",
    "                else:\n",
    "                    template = template_func(type=\"item\", invocations=invocations.get(id_, []), content=row_dict)\n",
    "            res.append(str(template))\n",
    "\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def embedding_path(self):\n",
    "        embedding_path = os.path.join(RESOURCE_DIR, \"embedding\")\n",
    "        if not os.path.exists(embedding_path):\n",
    "            os.makedirs(embedding_path)\n",
    "        return embedding_path\n",
    "\n",
    "    def get_models(self, type_: EmbeddingModel) -> Union[HuggingFaceEmbeddings, HuggingFaceInstructEmbeddings]:\n",
    "        model, model_name = embedding_models[type_.value]\n",
    "        return model(model_name=model_name)\n",
    "\n",
    "    def save_embedding(self, embed_data, embed_name):\n",
    "        saved_path = os.path.join(self.embedding_path, embed_name)\n",
    "        if not os.path.exists(saved_path):\n",
    "            np.save(saved_path, embed_data)\n",
    "\n",
    "    def load_embedding(self, embed_name):\n",
    "        saved_path = os.path.join(\n",
    "            self.embedding_path, embed_name + self.suffix)\n",
    "        if not os.path.exists(saved_path):\n",
    "            raise FileNotFoundError\n",
    "        return np.load(saved_path)\n",
    "\n",
    "    def fit(self, type_: EmbeddingType, template_type: TemplateType, model_type: EmbeddingModel, auto_save=True, *arg, **kwarg):\n",
    "        combined_string = f\"{type_.value}_{template_type.value}_{model_type.value}\"\n",
    "        file_name = hashlib.md5(combined_string.encode()).hexdigest()[:6]\n",
    "        try:\n",
    "            return self.load_embedding(file_name)\n",
    "        except FileNotFoundError as e:\n",
    "            pass\n",
    "        model = self.get_models(model_type)\n",
    "        embeddings = model.embed_documents(\n",
    "            self.info2template(type_, template_type, kwarg[\"invocations\"]))\n",
    "        if auto_save:\n",
    "            self.save_embedding(embeddings, file_name)\n",
    "        return embeddings\n",
    "\n",
    "eh = EmbeddingHelper()\n",
    "eh.fit(EmbeddingType.USER, TemplateType.IMPROVED,\n",
    "        EmbeddingModel.INSTRUCTOR_BGE_SMALL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
